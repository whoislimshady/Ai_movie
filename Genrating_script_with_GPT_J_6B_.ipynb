{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genrating script with GPT-J-6B .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoislimshady/Ai_movie/blob/main/Genrating_script_with_GPT_J_6B_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7xAFw-LOYfe",
        "outputId": "f8cf749d-f3a9-4a1d-950e-dadc170b5630"
      },
      "source": [
        "!apt install zstd\n",
        "\n",
        "# the \"slim\" version contain only bf16 weights and no optimizer parameters, which minimizes bandwidth and memory\n",
        "!time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "\n",
        "!time tar -I zstd -xf step_383500_slim.tar.zstd\n",
        "\n",
        "!git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "!pip install -r mesh-transformer-jax/requirements.txt\n",
        "\n",
        "# jax 0.2.12 is required due to a regression with xmap in 0.2.13\n",
        "!pip install mesh-transformer-jax/ jax==0.2.12 tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 278 kB of archives.\n",
            "After this operation, 1,141 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 zstd amd64 1.3.3+dfsg-2ubuntu1.2 [278 kB]\n",
            "Fetched 278 kB in 1s (332 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Setting up zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2022-05-31 06:27:40--  https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
            "Resolving the-eye.eu (the-eye.eu)... 162.213.130.6\n",
            "Connecting to the-eye.eu (the-eye.eu)|162.213.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9414712325 (8.8G) [application/octet-stream]\n",
            "Saving to: ‘step_383500_slim.tar.zstd’\n",
            "\n",
            "p_383500_slim.tar.z   8%[>                   ] 799.98M  70.9MB/s    eta 1m 59s "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1UXepF-0Uq"
      },
      "source": [
        "## Setup Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0qJgaueZtJ"
      },
      "source": [
        "import os\n",
        "import requests \n",
        "from jax.config import config\n",
        "\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "requests.post(url)\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIgUVdFLe4A8"
      },
      "source": [
        "Sometimes the next step errors for some reason, just run it again ¯\\\\\\_(ツ)\\_/¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5IGYSaeze3"
      },
      "source": [
        "import time\n",
        "\n",
        "import jax\n",
        "from jax.experimental import maps\n",
        "import numpy as np\n",
        "import optax\n",
        "import transformers\n",
        "\n",
        "from mesh_transformer.checkpoint import read_ckpt_lowmem\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgKq-X2kmba"
      },
      "source": [
        "params = {\n",
        "  \"layers\": 28,\n",
        "  \"d_model\": 4096,\n",
        "  \"n_heads\": 16,\n",
        "  \"n_vocab\": 50400,\n",
        "  \"norm\": \"layernorm\",\n",
        "  \"pe\": \"rotary\",\n",
        "  \"pe_rotary_dims\": 64,\n",
        "\n",
        "  \"seq\": 2048,\n",
        "  \"cores_per_replica\": 8,\n",
        "  \"per_replica_batch\": 1,\n",
        "}\n",
        "\n",
        "per_replica_batch = params[\"per_replica_batch\"]\n",
        "cores_per_replica = params[\"cores_per_replica\"]\n",
        "seq = params[\"seq\"]\n",
        "\n",
        "\n",
        "params[\"sampler\"] = nucleaus_sample\n",
        "\n",
        "# here we \"remove\" the optimizer parameters from the model (as we don't need them for inference)\n",
        "params[\"optimizer\"] = optax.scale(0)\n",
        "\n",
        "mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "\n",
        "maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "\n",
        "tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFgRkUgfiNdA"
      },
      "source": [
        "Here we create the network and load the parameters from the downloaded files. Expect this to take around 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNETD2Uk8nu"
      },
      "source": [
        "total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "network = CausalTransformer(params)\n",
        "\n",
        "network.state = read_ckpt_lowmem(network.state, \"step_383500/\", devices.shape[1])\n",
        "\n",
        "network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BEb3O5opWQ7"
      },
      "outputs": [],
      "source": [
        "# allow text wrapping in generated output: https://stackoverflow.com/a/61401455\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzs2TYlvYeX"
      },
      "source": [
        "def infer(context, top_p=0.9, temp=1.0, gen_len=512):\n",
        "    tokens = tokenizer.encode(context)\n",
        "\n",
        "    provided_ctx = len(tokens)\n",
        "    pad_amount = seq - provided_ctx\n",
        "\n",
        "    padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "    batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "    length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "    start = time.time()\n",
        "    output = network.generate(batched_tokens, length, gen_len, {\"top_p\": np.ones(total_batch) * top_p, \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "    samples = []\n",
        "    decoded_tokens = output[1][0]\n",
        "\n",
        "    for o in decoded_tokens[:, :, 0]:\n",
        "      samples.append(f\"\\033[1m{context}\\033[0m{tokenizer.decode(o)}\")\n",
        "\n",
        "    print(f\"completion done in {time.time() - start:06}s\")\n",
        "    return samples\n",
        "\n",
        "print(infer(\"\"\"A BAD MIDDLE SCHOOL BAND PLAYS THE DISNEY LOGO THEME.\n",
        "ONCE IT ENDS...\n",
        "JOE (O.S.)\n",
        "Alright! Let’s try something else.\n",
        "Uh...from the top. Ready? One, two,\n",
        "three...\n",
        "INT. MIDDLE SCHOOL BAND ROOM.\n",
        "JOE GARDNER, a passionate, well-dressed middle-aged man,\n",
        "conducts an off-key middle school band. It’s painfully bad.\n",
        "JOE\n",
        "One, two, three, four! Stay on the\n",
        "beat! Two, three four--that’s a C\n",
        "Sharp, horns!\n",
        "A TROMBONIST loses his trombone end, which lands on the floor\n",
        "with a CLANK.\n",
        "A TRUMPETER uses his horn to vacuum up M&Ms from the floor.\n",
        "CALEB, a saxophonist, pretends to play while actually on his\n",
        "iPHONE.\n",
        "JOE\n",
        "Two, three, I see you, Caleb!\n",
        "Startled, Caleb tosses the phone into a neighboring student’s\n",
        "sax.\n",
        "JOE\n",
        "(to another student)\n",
        "Rachel, now you!\n",
        "But Rachel lies across a few chairs.\n",
        "RACHEL\n",
        "Forgot my sax, Mr. G.\n",
        "JOE\n",
        "Okay, she forgot her sax! Aaand now-\n",
        "- aaaaall you, Connie. Go for it!\n",
        "Joe then motions to CONNIE, a Chinese American girl holding a\n",
        "trombone. She’s his last hope.\n",
        "Connie plays her solo, strong and passionate. Joe smiles.\n",
        "But some of the other kids start giggling, and Connie’s\n",
        "confidence (and playing) suddenly wilts.\"\"\")[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvlAK6RbCJYg"
      },
      "source": [
        "\n",
        "\n",
        "context = \"\"\"A BAD MIDDLE SCHOOL BAND PLAYS THE DISNEY LOGO THEME.\n",
        "ONCE IT ENDS...\n",
        "JOE (O.S.)\n",
        "Alright! Let’s try something else.\n",
        "Uh...from the top. Ready? One, two,\n",
        "three...\n",
        "INT. MIDDLE SCHOOL BAND ROOM.\n",
        "JOE GARDNER, a passionate, well-dressed middle-aged man,\n",
        "conducts an off-key middle school band. It’s painfully bad.\n",
        "JOE\n",
        "One, two, three, four! Stay on the\n",
        "beat! Two, three four--that’s a C\n",
        "Sharp, horns!\n",
        "A TROMBONIST loses his trombone end, which lands on the floor\n",
        "with a CLANK.\n",
        "A TRUMPETER uses his horn to vacuum up M&Ms from the floor.\n",
        "CALEB, a saxophonist, pretends to play while actually on his\n",
        "iPHONE.\n",
        "JOE\n",
        "Two, three, I see you, Caleb!\n",
        "Startled, Caleb tosses the phone into a neighboring student’s\n",
        "sax.\n",
        "JOE\n",
        "(to another student)\n",
        "Rachel, now you!\n",
        "But Rachel lies across a few chairs.\n",
        "RACHEL\n",
        "Forgot my sax, Mr. G.\n",
        "JOE\n",
        "Okay, she forgot her sax! Aaand now-\n",
        "- aaaaall you, Connie. Go for it!\n",
        "Joe then motions to CONNIE, a Chinese American girl holding a\n",
        "trombone. She’s his last hope.\n",
        "Connie plays her solo, strong and passionate. Joe smiles.\n",
        "But some of the other kids start giggling, and Connie’s\n",
        "confidence (and playing) suddenly wilts.\"\"\"\n",
        "\n",
        "print(infer(top_p=top_p, temp=temp, gen_len=512, context=context)[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}